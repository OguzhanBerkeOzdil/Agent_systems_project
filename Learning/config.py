# config.py

# Grid dimensions
GRID_SIZE = 15
CELL_SIZE = 40
DAY_BG_COLOR = (100, 149, 237)
NIGHT_BG_COLOR = (25, 25, 112)
UI_FONT_COLOR = (255, 255, 255)
UI_HEIGHT = 0
CHART_HEIGHT = 0

# extra width reserved for debug log panel
LOG_PANEL_WIDTH = 200

WINDOW_WIDTH = GRID_SIZE * CELL_SIZE + LOG_PANEL_WIDTH
WINDOW_HEIGHT = GRID_SIZE * CELL_SIZE + UI_HEIGHT + CHART_HEIGHT
WINDOW_SIZE = (WINDOW_WIDTH, WINDOW_HEIGHT)

FPS = 30

ORC_COLOR = (255, 0, 0)
DWARF_COLOR = (0, 0, 255)
PREDATOR_HIGHLIGHT = (255, 255, 0)

NUM_ORCS = 10
NUM_DWARVES = 10
DAY_DURATION = 50

PREDATOR_ENERGY_LOSS = 0.2
PREY_ENERGY_LOSS = 0.2
PREDATOR_ENERGY_GAIN = 15
REPRODUCTION_THRESHOLD = 40
INITIAL_PREDATOR_ENERGY = 40
INITIAL_PREY_ENERGY = 40

REINFORCEMENT_INTERVAL = 50
REINFORCEMENT_ENERGY_BOOST = 10
REINFORCEMENT_NEW_ORCS = 2
REINFORCEMENT_NEW_DWARVES = 3

OBSTACLE_COUNT = 20
OBSTACLE_COLOR = (128, 128, 128)

ANIMATION_STEPS = 10

BACKGROUND_MUSIC = "assets/The Battle of the Pelennor Fields.mp3"
REPRODUCTION_SOUND = "assets/reproduce.wav"

SHOW_HEATMAP = False

DWARF_REPRODUCTION_THRESHOLD = 50
DWARF_REPRODUCTION_COST = 0.75

RESOURCE_NODE_COUNT = 5
RESOURCE_NODE_ENERGY = 20
RESOURCE_NODE_RESPAWN_INTERVAL = 100

WEATHER_CHANGE_INTERVAL = 100
WEATHER_STATES = ["clear", "rain", "storm"]
RAIN_ENERGY_LOSS_INCREASE = 0.05
STORM_ENERGY_LOSS_INCREASE = 0.1
STORM_MOVEMENT_SLOWDOWN = 0.5

PACK_RADIUS = 3
PACK_ENERGY_BONUS_MULTIPLIER = 0.1

# Fallback/global traits
MIN_SPEED = 1.0
MAX_SPEED = 3.0
MIN_VISION_RADIUS = 3
MAX_VISION_RADIUS = 8

KILL_PARTICLE_COUNT = 15
KILL_PARTICLE_LIFETIME = 0.5

MINIMAP_SCALE = 0.2
MINIMAP_PADDING = 10

HIGH_SCORE_FILE = "highscore.txt"

DAY_TEMP_MULTIPLIER = 1.0
NIGHT_TEMP_MULTIPLIER = 1.2

MAX_AGE = 200
TRAIL_LENGTH = 10

RESOURCE_RESPAWN_TIMER = RESOURCE_NODE_RESPAWN_INTERVAL

LOG_OVERLAY_MAX = 5

HEALTH_BAR_HEIGHT = 5

# Species-specific traits
ORC_MIN_SPEED = 1.5
ORC_MAX_SPEED = 3.0
DWARF_MIN_SPEED = 1.0
DWARF_MAX_SPEED = 2.0

ORC_MIN_VISION_RADIUS = 5
ORC_MAX_VISION_RADIUS = 8
DWARF_MIN_VISION_RADIUS = 3
DWARF_MAX_VISION_RADIUS = 6

# End conditions
MAX_TURNS = 5000

# -- Reinforcement Learning (Q-Learning) parameters --

# learning rate
ALPHA = 0.1
# discount factor
GAMMA = 0.9
# exploration rate ε for ε-greedy
EPSILON = 0.1

# -- Energy & reward settings for learning agents --

# maximum energy an agent can hold
MAX_ENERGY = 100
# energy lost per simulation step
ENERGY_LOSS_PER_STEP = 1
# energy gained when eating a resource node
ENERGY_GAIN_PER_EAT = RESOURCE_NODE_ENERGY
